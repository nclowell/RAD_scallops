{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CRAGIG Runs 1 and 2 through ipyrad\n",
    "\n",
    "**20170605**\n",
    "\n",
    "I'm going to run all my current scallop RAD data through the ipyrad pipeline because as of yet I have only run it on ten samples at a time to get the hang of it and to see preliminary differences between Stacks and ipyrad.\n",
    "\n",
    "First, I need to demultiplex my two lanes of data. For each, I'll make a unique params file for each library and then I'll merge them together.\n",
    "\n",
    "The two params files will differ only in the location of the raw data fastq file and the barcodes files.\n",
    "\n",
    "cragig007 will be for CRAGIG_run1 and cragig008 will be for CRAGIG_run2\n",
    "\n",
    "This is what's in cragig007:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mbarcodes_cragigrun1.txt\u001b[0m*  \u001b[01;32mparams-cragig007.txt\u001b[0m*\r\n",
      "\u001b[01;32mbarcodes_cragigrun2.txt\u001b[0m*  \u001b[01;32mpopmap_cragig007.txt\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ipyrad params file (v.0.6.20)-------------------------------------------\r\n",
      "cragig007                      ## [0] [assembly_name]: Assembly name. Used to name output directories for assembly steps\r\n",
      "./                             ## [1] [project_dir]: Project dir (made in curdir if not present)\r\n",
      "../../../Data/CRAGIG_RUN1_rawdata/161228_I137_FCHCYV5BBXX_L5_CHKPE85216120009_2.fq.gz                               ## [2] [raw_fastq_path]: Location of raw non-demultiplexed fastq files\r\n",
      "./barcodes_cragigrun1.txt     ## [3] [barcodes_path]: Location of barcodes file\r\n",
      "                              ## [4] [sorted_fastq_path]: Location of demultiplexed/sorted fastq files\r\n",
      "denovo                         ## [5] [assembly_method]: Assembly method (denovo, reference, denovo+reference, denovo-reference)\r\n",
      "                               ## [6] [reference_sequence]: Location of reference sequence file\r\n",
      "rad                            ## [7] [datatype]: Datatype (see docs): rad, gbs, ddrad, etc.\r\n",
      "TGCAGG,                         ## [8] [restriction_overhang]: Restriction overhang (cut1,) sbf1\r\n",
      "5                              ## [9] [max_low_qual_bases]: Max low quality base calls (Q<20) in a read\r\n",
      "33                             ## [10] [phred_Qscore_offset]: phred Q score offset (33 is default and very standard)\r\n",
      "10                              ## [11] [mindepth_statistical]: Min depth for statistical base calling\r\n",
      "10                              ## [12] [mindepth_majrule]: Min depth for majority-rule base calling\r\n",
      "5000                          ## [13] [maxdepth]: Max cluster depth within samples\r\n",
      "0.85                           ## [14] [clust_threshold]: Clustering threshold for de novo assembly\r\n",
      "0                              ## [15] [max_barcode_mismatch]: Max number of allowable mismatches in barcodes\r\n",
      "2                              ## [16] [filter_adapters]: Filter for adapters/primers (1 or 2=stricter)\r\n",
      "40                             ## [17] [filter_min_trim_len]: Min length of reads after adapter trim\r\n",
      "2                              ## [18] [max_alleles_consens]: Max alleles per site in consensus sequences\r\n",
      "5, 5                           ## [19] [max_Ns_consens]: Max N's (uncalled bases) in consensus (R1, R2)\r\n",
      "8, 8                           ## [20] [max_Hs_consens]: Max Hs (heterozygotes) in consensus (R1, R2)\r\n",
      "70                              ## [21] [min_samples_locus]: Min # samples per locus for output (total samples in run = 143)\r\n",
      "20, 20                         ## [22] [max_SNPs_locus]: Max # SNPs per locus (R1, R2)\r\n",
      "8, 8                           ## [23] [max_Indels_locus]: Max # of indels per locus (R1, R2)\r\n",
      "0.9                            ## [24] [max_shared_Hs_locus]: Max # heterozygous sites per locus (R1, R2)\r\n",
      "0, 0, 0, 0                     ## [25] [trim_reads]: Trim raw read edges (R1>, <R1, R2>, <R2) (see docs)\r\n",
      "0, 0, 0, 0                     ## [26] [trim_loci]: Trim locus edges (see docs) (R1>, <R1, R2>, <R2)\r\n",
      "*                              ## [27] [output_formats]: Output formats (see docs)\r\n",
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUN1_py/popmap_cragig007.txt                         ## [28] [pop_assign_file]: Path to population assignment file\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 30 params-cragig007.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "\n",
      "  A new version of ipyrad is available (v.0.6.27). To upgrade run:\n",
      "\n",
      "    conda install -c ipyrad ipyrad\n",
      "\n",
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  New Assembly: cragig007\n",
      "  host compute node: [6 cores] on ubuntu\n",
      "\n",
      "  Step 1: Demultiplexing fastq data to Samples\n",
      "  [####################] 100%  sorting reads         | 1:26:47  es  | 0:25:59  \n",
      "  [####################] 100%  writing/compressing   | 0:37:57  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-cragig007.txt -s 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "\n",
      "  A new version of ipyrad is available (v.0.6.27). To upgrade run:\n",
      "\n",
      "    conda install -c ipyrad ipyrad\n",
      "\n",
      "\n",
      " -------------------------------------------------------------\n",
      "  ipyrad [v.0.6.20]\n",
      "  Interactive assembly and analysis of RAD-seq data\n",
      " -------------------------------------------------------------\n",
      "  New Assembly: cragig008\n",
      "  host compute node: [6 cores] on ubuntu\n",
      "\n",
      "  Step 1: Demultiplexing fastq data to Samples\n",
      "  [##################  ]  92%  sorting reads         | 0:39:39  "
     ]
    }
   ],
   "source": [
    "!ipyrad -p params-cragig008.txt -s 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It kept crashing the jupyter notebook so I'm starting to run these outside the terminal. For some reason, even though I merged assemblies, it only ran on the first 71 samples. Here's what the params file looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ipyrad params file (v.0.6.20)-------------------------------------------\r\n",
      "cragig009                      ## [0] [assembly_name]: Assembly name. Used to name output directories for assembly steps\r\n",
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py ## [1] [project_dir]: Project dir (made in curdir if not present)\r\n",
      "Merged: cragig007, cragig008   ## [2] [raw_fastq_path]: Location of raw non-demultiplexed fastq files\r\n",
      "Merged: cragig007, cragig008   ## [3] [barcodes_path]: Location of barcodes file\r\n",
      "Merged: cragig007, cragig008   ## [4] [sorted_fastq_path]: Location of demultiplexed/sorted fastq files\r\n",
      "denovo                         ## [5] [assembly_method]: Assembly method (denovo, reference, denovo+reference, denovo-reference)\r\n",
      "                               ## [6] [reference_sequence]: Location of reference sequence file\r\n",
      "rad                            ## [7] [datatype]: Datatype (see docs): rad, gbs, ddrad, etc.\r\n",
      "TGCAGG,                        ## [8] [restriction_overhang]: Restriction overhang (cut1,) or (cut1, cut2)\r\n",
      "5                              ## [9] [max_low_qual_bases]: Max low quality base calls (Q<20) in a read\r\n",
      "33                             ## [10] [phred_Qscore_offset]: phred Q score offset (33 is default and very standard)\r\n",
      "10                             ## [11] [mindepth_statistical]: Min depth for statistical base calling\r\n",
      "10                             ## [12] [mindepth_majrule]: Min depth for majority-rule base calling\r\n",
      "5000                           ## [13] [maxdepth]: Max cluster depth within samples\r\n",
      "0.85                           ## [14] [clust_threshold]: Clustering threshold for de novo assembly\r\n",
      "0                              ## [15] [max_barcode_mismatch]: Max number of allowable mismatches in barcodes\r\n",
      "2                              ## [16] [filter_adapters]: Filter for adapters/primers (1 or 2=stricter)\r\n",
      "40                             ## [17] [filter_min_trim_len]: Min length of reads after adapter trim\r\n",
      "2                              ## [18] [max_alleles_consens]: Max alleles per site in consensus sequences\r\n",
      "5, 5                           ## [19] [max_Ns_consens]: Max N's (uncalled bases) in consensus (R1, R2)\r\n",
      "8, 8                           ## [20] [max_Hs_consens]: Max Hs (heterozygotes) in consensus (R1, R2)\r\n",
      "70                             ## [21] [min_samples_locus]: Min # samples per locus for output\r\n",
      "20, 20                         ## [22] [max_SNPs_locus]: Max # SNPs per locus (R1, R2)\r\n",
      "8, 8                           ## [23] [max_Indels_locus]: Max # of indels per locus (R1, R2)\r\n",
      "0.9                            ## [24] [max_shared_Hs_locus]: Max # heterozygous sites per locus (R1, R2)\r\n",
      "0, 0, 0, 0                     ## [25] [trim_reads]: Trim raw read edges (R1>, <R1, R2>, <R2) (see docs)\r\n",
      "0, 0, 0, 0                     ## [26] [trim_loci]: Trim locus edges (see docs) (R1>, <R1, R2>, <R2)\r\n",
      "G, a, g, k, m, l, n, p, s, u, t, v ## [27] [output_formats]: Output formats (see docs)\r\n",
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py/popmap_cragig007.txt ## [28] [pop_assign_file]: Path to population assignment file"
     ]
    }
   ],
   "source": [
    "!head -n 30 params-cragig009.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Trouble!\n",
    "\n",
    "**20170608**\n",
    "\n",
    "Aw bummer. It looks like the fastsq files for both cragig007 and cragig0008 are the same, so I might have goofed in what files I fed it. Double-checking the params files now... Found it! I didn't use the correct barcodes file (I used the one for CRAGIG_run1 for both cragig007 and cragig008). Going to double-check the params files and rerun.\n",
    "\n",
    "Watching it rerun and ipyrad knows to delete all old files when I force the step to rewrite over the previous version. That's pretty cool!\n",
    "\n",
    "I'm not totally sure that I know how to use the merge operation well yet, as it spit out an error during Step 2:\n",
    "```\n",
    "ERROR \tIPyradError(error in: ['cat', '/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py/cragig007_fastqs/FG034_R1_.fastq.gz', '/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py/cragig008_fastqs/FG034_R1_.fastq.gz'], None)\n",
    "```\n",
    "\n",
    "I'm going to rerun evertyhing from the start, and double-check I have the merge function well understood.\n",
    "\n",
    "**20170609**\n",
    "\n",
    "I read the documentation more carefully and indeed I understand everything right. My mistake was that I accidentally used the same barcodes file, which meant ipyrad thought that I wanted to concatenate data from different fastq files into the same sample. Then, when it couldn't find things to concatenate, it got confused. The command to merge multiple libraries from multiple lanes is the same as one library in multiple lanes, it just results in a different outcome. Running now!\n",
    "\n",
    "**20170612**\n",
    "\n",
    "The pipeline ran totally fine except during Step 7 I got this error message:\n",
    "\n",
    "```\n",
    "ERROR:ipyrad.core.assembly:IPyradWarningExit: \n",
    "    Exception: empty varcounts array. This could be because no samples \n",
    "    passed filtering, or it could be because you have overzealous filtering.\n",
    "    Check the values for `trim_loci` and make sure you are not trimming the\n",
    "    edge too far\n",
    "\n",
    "```\n",
    "\n",
    "I checked the ``trim_loci`` parameter, and I have it set to 0,0,0,0 which means it doesn't trim edges at all, so I don't think that the values for ``trim_loci`` were the problem.\n",
    "\n",
    "I made a list of all the parameters that affect Step 7 to see if I could check each one/trouble-shoot.\n",
    "\n",
    "- 18 - max alleles consens\n",
    "- 21 - min samples locus\n",
    "- 22 - max SNPs locus\n",
    "- 23 - max indels locus\n",
    "- 24 - max shared Hs locus\n",
    "- 26 - trim loci\n",
    "- 27 - output formats\n",
    "- 28 - pop assign file\n",
    "\n",
    "I went through the stats output files for each step to see if it's obvious where the samples are getting filtered out. Here, I'll compare to the params file from my test run of ipyrad on 10 scallops and that assembly's output stats files.\n",
    "\n",
    "## Trouble-shooting\n",
    "\n",
    "### Comparing params files of cragig009 and test run that worked fine\n",
    "\n",
    "Parameters from the list above that differed:\n",
    "* **21 - min samples locus**: was set to 4 (4 samples per locus required to report to output) in cragig004 and to 70 for cragig009. But, cragig004 only had 10 samples so 4/10 = 40% and cragig009 had 143 samples, so 70/143 = 49%, which isn't that different. I have trouble believing this would be the culprit for the difference in outcomes, but it'd be worth a shot to reduce it. \n",
    "\n",
    "Aaand that's the only paramter that's different from the list. Weird! I just chatted with some lab mates who don't think that that should have created the result that I'm seeing (no samples making it through filtering).\n",
    "\n",
    "Let's try the infamous \"Have you tried powering it off, and back on again?\" and forcing to rerun Step 7.\n",
    "\n",
    "Bummer - got the same error message.\n",
    "\n",
    "Now I'm going to try lowering the value for parameter 21 from 70 to 25 and then seeing if that changes anything. I'll do this through a branching assembly and naming the branch cragig010. Now running Step 7 of cragig010...\n",
    "\n",
    "Oh no! I got the same exact error message. This makes me think that it's not parameter 21, although just to be doubly sure, I'm going to make cragig011 and set the value to 4 as it was in cragig004. And, I got the same error message again. It's not that parameter. I'm now going to compare the stats output files from the test run (cragig004) and cragig009 to see which step before Step 7 could have caused this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comparing output stats files from different steps in cragig009 and test run that worked fine\n",
    "\n",
    "I have no good way of looking at any singular stats output file and discerning whether the step is overzealous in it's filtering, or causing some issue. But, cragig004-006 all produced a normal seeming number of loci, and all samples made it through filtering steps with pretty much the same parameters. So I'm going to compare those to see if I can pinpoint what is different between cragig004-006 and cragig009 that may have caused this issue.\n",
    "\n",
    "#### s3_cluster_stats.txt\n",
    "\n",
    "Visually, these files seem to have really similar values. \n",
    "\n",
    "![img](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_combined_lanes/Notebooks/imgs_for_notebooks/comp_s3_cragig004_009.png?raw=true)\n",
    "\n",
    "Below, I practiced using Kolmogorovâ€“Smirnov test from ``scipy`` which said the distributions are different, and I'm not sure why that is when visually they look so similar. I wonder if it just as to do with sample size, as cragig009 has 14x as many samples as cragig004.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUNS_12_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3_009 = open(\"cragig009_clust_0.85/s3_cluster_stats.txt\",\"r\")\n",
    "s3_009_lines = s3_009.readlines()\n",
    "s3_009.close()\n",
    "\n",
    "clusters_total_009 = []\n",
    "clusters_hidepth_min_009 = []\n",
    "avg_depth_total_009 = []\n",
    "avg_depth_mj_009 = []\n",
    "sd_depth_total_009 = []\n",
    "sd_depth_mj_009 = []\n",
    "\n",
    "for line in s3_009_lines[1:]: # iterate over lines, exclude header\n",
    "    linelist = line.strip().split()\n",
    "    clusters_total_009.append(float(linelist[1]))\n",
    "    clusters_hidepth_min_009.append(float(linelist[3])) \n",
    "    avg_depth_total_009.append(float(linelist[4]))\n",
    "    avg_depth_mj_009.append(float(linelist[5]))\n",
    "    sd_depth_total_009.append(float(linelist[7]))\n",
    "    sd_depth_mj_009.append(float(linelist[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUN1_py\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/hgfs/SHARED_FOLDER/Learn_iPyrad/CRAGIG_RUN1_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3_004 = open(\"cragig004_clust_0.85/s3_cluster_stats.txt\",\"r\")\n",
    "s3_004_lines = s3_004.readlines()\n",
    "s3_004.close()\n",
    "\n",
    "clusters_total_004 = []\n",
    "clusters_hidepth_min_004 = []\n",
    "avg_depth_total_004 = []\n",
    "avg_depth_mj_004 = []\n",
    "sd_depth_total_004 = []\n",
    "sd_depth_mj_004 = []\n",
    "\n",
    "for line in s3_004_lines[1:]: # iterate over lines, exclude header\n",
    "    linelist = line.strip().split()\n",
    "    clusters_total_004.append(float(linelist[1]))\n",
    "    clusters_hidepth_min_004.append(float(linelist[3])) \n",
    "    avg_depth_total_004.append(float(linelist[4]))\n",
    "    avg_depth_mj_004.append(float(linelist[5]))\n",
    "    sd_depth_total_004.append(float(linelist[7]))\n",
    "    sd_depth_mj_004.append(float(linelist[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.51118881118881121, pvalue=0.009070706460590371)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(clusters_total_004,clusters_total_009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.41118881118881118, pvalue=0.060924309190217511)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(clusters_hidepth_min_004,clusters_hidepth_min_009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.49020979020979022, pvalue=0.01399709655173435)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(avg_depth_total_004,avg_depth_total_009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.4972027972027972, pvalue=0.012137132869640509)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(avg_depth_mj_004,avg_depth_mj_009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.68321678321678325, pvalue=0.00013032710397125613)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(sd_depth_total_004,sd_depth_total_009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.65524475524475523, pvalue=0.00028234576079832346)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(sd_depth_mj_004,sd_depth_mj_009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### s4_joint_estimate.txt\n",
    "\n",
    "Visually, the joint estimates of error and heterozygosity also don't look dramatically different:\n",
    "\n",
    "![img](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_combined_lanes/Notebooks/imgs_for_notebooks/comp_s4_cragig004-009.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### s5_consens_stats.txt\n",
    "\n",
    "Visually, the consensus base calling results don't look dramatically different either:\n",
    "\n",
    "![img](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_combined_lanes/Notebooks/imgs_for_notebooks/comp_s5_cragig004-009.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### s6_cluster_stats.txt\n",
    "\n",
    "Visually, the results from clustering consensus sequences do look a a little different, although it could be due to sample size. I'll need to be sure I understand each part well before I pass judgement.\n",
    "\n",
    "![imge](https://github.com/nclowell/RAD_Scallops/blob/master/CRAGIG_combined_lanes/Notebooks/imgs_for_notebooks/comp_s6_cragig004_009.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For example, the number of clusters of consensus sequences was 434,306 (Size min 1, max 7475, avg 7.0) for cragig009 and 76,218 (Size min 1, max 424, avg 2.8), but I'd think that's just the result of differences in sample size. If I understand this step, it's behaving like cstacks and clustering consensus sequences between samples. So, we'd assume that with more samples we'd have more consensus sequences that could be different.\n",
    "\n",
    "The number of singletons was 339,823 (11.2% of seqs, 78.2% of clusters) for cragig009 and 50,939 (23.6% of seqs, 66.8% of clusters). I imagine that that also has to do with sample size. I interpret a singleton here to mean that some consensus sequences only appear once across samples. But I'm not sure about the distinction between % sequences and % clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Troubleshooting After Communication with Developers\n",
    "\n",
    "**20170613**\n",
    "\n",
    "Messaged the ipyrad authors and they said that the last line in the population map specifies the minimum number of individuals in a population that a locus must appear in in order to be retained, and that this overrides the min sample param21. So, they advised that I remove the population map and set the min sample param21 pretty low, and let that inform me how high I should set the per population values.\n",
    "\n",
    "I made a new branch called **cragig012** where I made a new population assignment file and lowered each population number down to 1, and min samples down to 3. This time, Step 7 ran to completion without the error! Looks like there's few loci retained though, on the order of 2000ish per sample.\n",
    "\n",
    "Ok now - I'll make **cragig013** where I exclude the population assignment file and try 25 for min sample number. Oh no! I got the same error again >.< What a bummer.\n",
    "\n",
    "I'm going to try **cragig014** where I exclude the population assignment file and also lower min sample number to 10. Huh! None made it through this time either.\n",
    "\n",
    "As part of this trouble-shooting, it occurred to me that when I ran cragig004-006, that I had a population assignment file with the max number of individuals per population, and it still didn't filter out all my loci (which doesn't make sense to me). I'm curious about what will happen if I remove the population assignment file, and set the min samples locus param21 to 5 (has to be in half the scallops, doesn't matter what population). This will be **cragig015**. That worked, and produced 4773 loci per sample. What about if I lower param21 to 3? Does it affect retained loci predictably? Will do in **cragig016**. Not really - the number of retained loci was almost identical, at 4770 loci per sample.\n",
    "\n",
    "I'm still confused because when I work with the subset (10 scallops), I can set param21 to half the number of individuals and I still keep 4770 loci, but if I set param21 to 10 out of 143 for the total set of samples, I retain no individuals.\n",
    "\n",
    "Ok next thing to try - remove FG100_A, which had no retained loci, and see if assembly works fine after that. I manually moved the fastq out of that folder into the directory above it, and then I'm going to make a params file (**cragig017**) that is like cragig009 except I'll set param21 to 10 and exclude a population assignment file. I'm not sure if excluding samples is just a matter of moving fastq files, or if ipyrad calls individuals using the barcodes file or the population assignment file. So trying the fastq file removal idea first. Ugh, same error. Let me see in the stats file if it at least excluded FG100_A. Doesn't look like it got removed.\n",
    "\n",
    "I got some ubuntu error while **cragig018** was running overnight. I also realized that demutliplexing didn't overwrite my original fastqs, and there was something else I wanted to test before trying demultiplexing again in order to exclude FG100_A, and that was removing whatever file's step 7 must take from (the consensus files of steps 5-6?). Going to poke around the directory structure now.\n",
    "\n",
    "Worth removing FG100_A files from consens folder and rerunning step 7, although I have a feeling if FG100A messed up the process, that I'd need to repeat all steps that work between samples (at least steps 5 & 6). Ran: ``ipyrad -p params-cragig013.txt -s 7 -f``. Oh no! It didn't work either. Gonna look at the stats out file from step 7 to see whether there were 143 samples in the run (as in, did removing the consens files for FG100A actually remove it from the assembly). Ah! Still 143 samples, so it didn't actually remove FG100A.\n",
    "\n",
    "This is getting really messy and I'm not getting very far in sorting out what's causing all my samples to get filtered out. Also, I'm going to try rerunning **cragig018** now and getting some dumb error about the temp chunks folder for cragig018 being not empty (even though it looks empty?) so I made **cragig020**, which also excluded the pop assignment file and used barcodes sans replicates. Sweet! That worked. Now I have **cragig021** as the merged assembly. Going to go in and make the rest of the parameters just like **cragig004** (which worked) aka set param13 to 2000, param17 to 35. Also removed population assignment file, and set param21 to 10. Because I still think that's super liberal!\n",
    "\n",
    "A new error message altogether! **cragig021** ran through step 6 fine, and then in step 7 spit out this error message:\n",
    "```\n",
    "  Encountered an unexpected error (see ./ipyrad_log.txt)\n",
    "  Error message is below -------------------------------\n",
    "'FG102_A'\n",
    "```\n",
    "What's weird is FG102_A isn't the name of any of the samples in this run. However, in **cragig008**, I did use a population assignment file that included that sample, so maybe I just don't know how ipyrad works, and it's confused why there's a sample in the population assignment file and not in the fastqs, consens files, etc. I'm going to try a nifty trick Katherine told me about. You can remove samples from assembly by making a branch and calling:\n",
    "\n",
    "``ipyrad -p params-file.txt -b branchname - sample1 sample2 sample3``\n",
    "\n",
    "So, here, I'm running:\n",
    "\n",
    "``ipyrad -p params-cragig021.txt -b cragig021_sansreps.txt - FG100_A FG100_B FG101_A FG101_B FG102_A FG102_B FG103_A FG103_B FG104_A FG105_B``\n",
    "\n",
    "Ugh. It says it doesn't know what those sample names are, which is a surprise because it spit out 'FG102_A' as an error. That makes me think that it's using the population assignment file in step 7 to call samples, but there are no files named FG102_A so it's confused. Going to try deleting the population assignment file out of **cragig008** and rerunning step 7 of **cragig021**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
